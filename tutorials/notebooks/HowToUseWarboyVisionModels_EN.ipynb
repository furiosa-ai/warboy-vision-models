{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0155b004",
   "metadata": {},
   "source": [
    "# How to Use Warboy Vision Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06acc516",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use this project with the YOLOv8n object detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88fc89",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c1f76d",
   "metadata": {},
   "source": [
    "### Create a Python Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0fece",
   "metadata": {},
   "source": [
    "To follow this tutorial, you need Python 3.9 or higher. If you already have your own Python 3.9 or higher environment, you can skip this step. Otherwise, you can create a new Python environment using Conda.\n",
    "\n",
    "First, if you don't have Conda installed, you can install Miniconda. Here are the commands to install Miniconda:\n",
    "```console\n",
    "$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "$ sh ./Miniconda3-latest-Linux-x86_64.sh\n",
    "$ rm -rf Miniconda3-latest-Linux-x86_64.sh\n",
    "$ source ~/.bashrc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d07d2d",
   "metadata": {},
   "source": [
    "After installing Miniconda, you can create a new Python environment using the following commands:\n",
    "\n",
    "```console\n",
    "$ conda create -n furiosa-3.9 python=3.9\n",
    "$ conda activate furiosa-3.9\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708863a",
   "metadata": {},
   "source": [
    "### Install Driver, Firmware, and Runtime packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab9f99",
   "metadata": {},
   "source": [
    "First, you can install the Driver, Firmware, and Runtime packages for the NPU device through the APT server. To do this, you need to set up the APT server. You can follow the instructions in [Korean](https://developer.furiosa.ai/docs/latest/ko/software/installation.html) or [English](https://developer.furiosa.ai/docs/latest/en/software/installation.html).\n",
    "\n",
    "After setting up the APT server, you can install the packages using the following command:\n",
    "\n",
    "```console\n",
    "$ sudo apt-get update && sudo apt-get install -y furiosa-driver-warboy furiosa-libnux\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4bc05",
   "metadata": {},
   "source": [
    "Next, you can check the NPU devices in your environment using the following command:\n",
    "\n",
    "```console\n",
    "$ sudo apt-get install -y furiosa-toolkit\n",
    "$ furiosactl info --format full\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a707a",
   "metadata": {},
   "source": [
    "### Install Furiosa Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5592b2",
   "metadata": {},
   "source": [
    "The Furiosa SDK can be installed using pip. You can check the details in [Korean](https://furiosa-ai.github.io/docs/latest/ko/) or [English](https://furiosa-ai.github.io/docs/latest/en/).\n",
    "\n",
    "```console\n",
    "$ pip install 'furiosa-sdk[full]'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c447550f",
   "metadata": {},
   "source": [
    "### Install Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c047e",
   "metadata": {},
   "source": [
    "If you have already downloaded the dataset, you can skip this step. However, please make sure to check the `CHECK` marks and verify the path of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728adc2",
   "metadata": {},
   "source": [
    "In this notebook, we will use the COCO dataset. You can download the COCO dataset using the following command:\n",
    "\n",
    "```console\n",
    "./coco.sh\n",
    "```\n",
    "This will download the COCO dataset and save it in the `datasets/coco` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93249448",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bf019",
   "metadata": {},
   "source": [
    "You can install the required packages using the following command:\n",
    "\n",
    "```console\n",
    "$ pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889eeaca",
   "metadata": {},
   "source": [
    "### Build Yolo Decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508394b0",
   "metadata": {},
   "source": [
    "In this project, C++ decoders are included for post-processing. You can build the decoders using the following command:\n",
    "\n",
    "```console\n",
    "$ ./build.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f9b80",
   "metadata": {},
   "source": [
    "### Install the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af406abc",
   "metadata": {},
   "source": [
    "To install the project as a module, you can use the following command:\n",
    "\n",
    "```console\n",
    "$ pip install .\n",
    "```\n",
    "This will install the project, allowing you to use the `warboy-vision` command line tool to run models on Warboy. You can check the details of the command line tool using the following command:\n",
    "\n",
    "```console\n",
    "$ warboy-vision --help\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e1344",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27ae0f",
   "metadata": {},
   "source": [
    "First, you need to prepare the configuration file for the model you want to use. In this notebook, we will use the YOLOv8n model. You can check the configuration file in `yolov8n.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.warboy.tools.onnx_tools import OnnxTools\n",
    "from src.warboy import get_model_params_from_cfg\n",
    "\n",
    "cfg = '../cfg/yolov8n.yaml'\n",
    "onnx_tools = OnnxTools(cfg)\n",
    "param = get_model_params_from_cfg(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9bb7c",
   "metadata": {},
   "source": [
    "### Export ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa980d4c",
   "metadata": {},
   "source": [
    "To run the model on Warboy, you need a quantized ONNX model. First, let's export the YOLOv8n model to ONNX format.\n",
    "\n",
    "\n",
    "For YOLO models, due to a drop in accuracy after quantization caused by the concatenation operator (which combines class results and box results along the channel axis at each anchor), we need to modify the model by removing the decoding part from the model output. You can do this by giving the `need_edit` argument as `True` when exporting the model to ONNX format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17178311",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_tools.export_onnx(need_edit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d702e",
   "metadata": {},
   "source": [
    "### Quantize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911b994",
   "metadata": {},
   "source": [
    "Next, let's quantize the ONNX model. Quantization is a technique that converts a high-precision (usually FP32) DL model to a lower precision (here, INT8), reducing the model size and memory cost, and improving the inference speed.\n",
    "\n",
    "During the quantization phase, we need to prepare the calibration dataset. The calibration dataset is used to calculate the calibration range. In this notebook, we will use COCO dataset for calibration.\n",
    "\n",
    "The calibration method and the number of calibration data configured in `tutorials/cfg/yolov8n.yaml` file can be changed. You can see the specifics of quantization and calibration methods options in [Korean](https://developer.furiosa.ai/docs/latest/ko/software/quantization.html) or [English](https://developer.furiosa.ai/docs/v0.5.0/en/advanced/quantization.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1991093",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_tools.quantize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594ba99",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc6aac",
   "metadata": {},
   "source": [
    "### End to End Performance Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182a402",
   "metadata": {},
   "source": [
    "Now, we will run the end-to-end performance test. This will run inference using the model on the COCO dataset and measure the mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ee6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.test_scenarios.e2e.object_det import test_warboy_yolo_accuracy_det\n",
    "\n",
    "test_warboy_yolo_accuracy_det(\n",
    "    cfg = cfg,\n",
    "    image_dir = \"../../datasets/coco/val2017\",  # CHECK you may change this path to your own path\n",
    "    annotation_file = \"../../datasets/coco/annotations/instances_val2017.json\",  # CHECK you may change this path to your own path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d272b",
   "metadata": {},
   "source": [
    "### Web Demo with Fast API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060eb53",
   "metadata": {},
   "source": [
    "To run the web demo, you need to prepare the demo configuration file. You need to **set the `input_path` in `tutorials/cfg/demo.yaml` file** to the path of the video you want to use for the web demo.\n",
    "\n",
    "After running the web demo, you can access it at `http://localhost:20001` or `http://0.0.0.0:20001`.\n",
    "\n",
    "If you're using a remote server, you should port forward the port 20001 to your local machine. You can do this by running the following command **at your local machine**:\n",
    "\n",
    "```console\n",
    "$ ssh -L 20001:localhost:20001 <username>@<ip_address>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.demo.demo import run_web_demo\n",
    "\n",
    "demo_cfg_path = '../cfg/demo.yaml'\n",
    "\n",
    "run_web_demo(\n",
    "    cfg_path = demo_cfg_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867d998",
   "metadata": {},
   "source": [
    "### NPU Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0346e",
   "metadata": {},
   "source": [
    "In Furiosa SDK, we provide a profiling tool to analyze the NPU performance of the model. The profiling tool is used to measure the execution time of each operation and identify performance bottlenecks.\n",
    "\n",
    "After running the command, the trace file will be saved in the `tutorials/models/trace` directory. You can visualize the trace analysis using the Chrome web browser's Trace Event Profiling Tool (chrome://tracing). This will help you understand the performance of the model and optimize it for better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cda200",
   "metadata": {},
   "source": [
    "You may encounter `OpenTelemetry trace error occurred. cannot send span to the batch span processor because the channel is full` warning messages when writing the trace file. However, you can safely ignore them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a948a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.test_scenarios.e2e.npu_performance import test_warboy_performance\n",
    "\n",
    "test_warboy_performance(\n",
    "    cfg = cfg,\n",
    "    num_device = 1,\n",
    "    trace_file_dir=\"../models/trace\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "furiosa-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
