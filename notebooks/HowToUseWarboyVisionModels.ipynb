{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0155b004",
   "metadata": {},
   "source": [
    "# How to Use Warboy Vision Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06acc516",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use this project with yolov8n object detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88fc89",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c1f76d",
   "metadata": {},
   "source": [
    "### Make Python Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0fece",
   "metadata": {},
   "source": [
    "To follow this tutorial, you need Python 3.8 or higher. If you already have your own Python environment, you can skip this step. Otherwise, you can create a new Python environment using Conda.\n",
    "\n",
    "First, here are the commands to install Miniconda:\n",
    "```console\n",
    "$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "$ sh ./Miniconda3-latest-Linux-x86_64.sh\n",
    "$ rm -rf Miniconda3-latest-Linux-x86_64.sh\n",
    "$ source ~/.bashrc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d07d2d",
   "metadata": {},
   "source": [
    "After installing Miniconda, you can create a new Python environment and install the Furiosa Python SDK using the following commands:\n",
    "\n",
    "```console\n",
    "$ conda create -n furiosa-3.9 python=3.9\n",
    "$ conda activate furiosa-3.9\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708863a",
   "metadata": {},
   "source": [
    "### Install Driver, Firmware, and Runtime packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab9f99",
   "metadata": {},
   "source": [
    "First, you can install the Driver, Firmware, and Runtime packages for the NPU device through the APT server. To do this, you need to set up the APT server. You can follow the instructions in [Korean](https://developer.furiosa.ai/docs/latest/ko/software/installation.html) or [English](https://developer.furiosa.ai/docs/latest/en/software/installation.html).\n",
    "\n",
    "After setting up the APT server, you can install the packages using the following command:\n",
    "\n",
    "```console\n",
    "$ sudo apt-get update && sudo apt-get install -y furiosa-driver-warboy furiosa-libnux\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4bc05",
   "metadata": {},
   "source": [
    "Next, you can check NPU devices on your environment using the following command:\n",
    "\n",
    "```console\n",
    "$ sudo apt-get install -y furiosa-toolkit\n",
    "$ furiosactl info --format full\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a707a",
   "metadata": {},
   "source": [
    "### Install Furiosa Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5592b2",
   "metadata": {},
   "source": [
    "The Furiosa SDK can be installed following instructions on [Korean](https://furiosa-ai.github.io/docs/latest/ko/) or [English](https://furiosa-ai.github.io/docs/latest/en/).\n",
    "\n",
    "```console\n",
    "$ pip install 'furiosa-sdk[full]'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c447550f",
   "metadata": {},
   "source": [
    "### Install Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c047e",
   "metadata": {},
   "source": [
    "If you have your own dataset or already downloaded the dataset, you can skip these steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728adc2",
   "metadata": {},
   "source": [
    "In this notebook, we will use the COCO dataset. You can download the COCO dataset using the following command:\n",
    "\n",
    "```console\n",
    "./coco.sh\n",
    "```\n",
    "This will download the COCO dataset and save it in the `datasets/coco` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d6ab4",
   "metadata": {},
   "source": [
    "Also, to run web demo, you need to install the demo videos. You can download the demo videos using the following command:\n",
    "\n",
    "```console\n",
    "./demo_videos.sh\n",
    "```\n",
    "\n",
    "This will download the demo videos and save them in the `datasets/demo_videos` directory. This includes the object detection and instacne segmentation videos in `datasets/demo_videos/detection` and pose estimation videos in `datasets/demo_videos/estimation` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93249448",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bf019",
   "metadata": {},
   "source": [
    "You can install the required packages using the following command:\n",
    "\n",
    "```console\n",
    "$ pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889eeaca",
   "metadata": {},
   "source": [
    "### Build Yolo Decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508394b0",
   "metadata": {},
   "source": [
    "In this project, C++ decoders are included for post-processing. You can build the decoders using the following command:\n",
    "\n",
    "```console\n",
    "$ ./build.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac306a",
   "metadata": {},
   "source": [
    "### Set Root Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf442f",
   "metadata": {},
   "source": [
    "We should change the working directory to the project's root and add it to `sys.path` to ensure that modules and packages can be imported correctly, regardless of where the script is run from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "os.chdir(ROOT)\n",
    "sys.path.insert(0, ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a44f4",
   "metadata": {},
   "source": [
    "### Installing a Custom CLI Tool (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b663bfcd",
   "metadata": {},
   "source": [
    "In this notebook, we won't be using the custom CLI tool, but if you want to use it, you can install our custom CLI tool to run vision models on Warboy using the following command:\n",
    "\n",
    "```console\n",
    "$ pip install .\n",
    "```\n",
    "This will install the `warboy-vision` command line tool, which you can use to run models on Warboy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e1344",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27ae0f",
   "metadata": {},
   "source": [
    "First, you need to prepare the configuration file for the model you want to use. In this notebook, we will use the YOLOv8n model. You can check the configuration file in `yolov8n.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warboy_vision_models.warboy.tools.onnx_tools import OnnxTools\n",
    "from warboy_vision_models.warboy import get_model_params_from_cfg\n",
    "\n",
    "cfg = 'notebooks/yolov8n.yaml'\n",
    "onnx_tools = OnnxTools(cfg)\n",
    "param = get_model_params_from_cfg(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9bb7c",
   "metadata": {},
   "source": [
    "### Export ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa980d4c",
   "metadata": {},
   "source": [
    "To run the model on Warboy, you need a quantized ONNX model. First, let's export the YOLOv8n model to ONNX format.\n",
    "\n",
    "\n",
    "For yolo models, due to a drop in accuracy after quantization caused by the concatenation operator (which combines class results and box results along the channel axis at each anchor), we need to modified the model by removing the decoding part from the model output. You can do this by giving the `need_edit` argument as `True` when exporting the model to ONNX format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17178311",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_tools.export_onnx(need_edit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d702e",
   "metadata": {},
   "source": [
    "### Quantize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911b994",
   "metadata": {},
   "source": [
    "Next, let's quantize the ONNX model. Quantization is a technique that converts a high-precision (usually FP32) DL model to a lower precision, reducing the model size and memory cost, and improving the inference speed. By quantizing the model, you can run efficient inference AI services.\n",
    "\n",
    "In quantization phase, we need to prepare the calibration dataset. The calibration dataset is used to calibrate the quantization parameters of the model. In this notebook, we will use COCO dataset for calibration.\n",
    "\n",
    "The calibration method and the number of calibration data configured in `yolov8n.yaml` file can be changed. You can see the specifics of quantization and calibration methods options in [Korean](https://developer.furiosa.ai/docs/latest/ko/software/quantization.html) or [English](https://developer.furiosa.ai/docs/v0.5.0/en/advanced/quantization.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1991093",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_tools.quantize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594ba99",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc6aac",
   "metadata": {},
   "source": [
    "### End to End Performance Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182a402",
   "metadata": {},
   "source": [
    "Now, we will run the end to end performance test. This will run the model to inference on the COCO dataset and measure the mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ee6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warboy_vision_models.tests.e2e.test_object_det import test_warboy_yolo_accuracy_det\n",
    "\n",
    "test_warboy_yolo_accuracy_det(\n",
    "    model_name = 'yolov8n', \n",
    "    model = param['onnx_i8_path'], \n",
    "    input_shape= param['input_shape'], \n",
    "    anchors= param['anchors'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d272b",
   "metadata": {},
   "source": [
    "### Web Demo with Fast API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060eb53",
   "metadata": {},
   "source": [
    "To run the web demo, you need to prepare the demo configuration file. You can check the configuration file in `demo_config.yaml` file.\n",
    "\n",
    "After running the web demo, you can access the web demo at `http://localhost:20001` or `http://0.0.0.0:20001`.\n",
    "\n",
    "If you're using a remote server, you should port foward the port 20001 to your local machine. You can do this by running the following command **at your local machine**:\n",
    "\n",
    "```console\n",
    "$ ssh -L 20001:localhost:20001 <username>@<ip_address>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warboy_vision_models.demo.demo import run_web_demo\n",
    "\n",
    "demo_cfg_path = 'notebooks/demo.yaml'\n",
    "\n",
    "run_web_demo(\n",
    "    cfg_path = demo_cfg_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867d998",
   "metadata": {},
   "source": [
    "### NPU Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0346e",
   "metadata": {},
   "source": [
    "In Furiosa SDK, we provide a profiling tool to analyze the performance of the model. You can use the profiling tool to measure the time taken by each operation in the model and identify the bottlenecks in the model.\n",
    "\n",
    "After running the command, the trace file will be saved in the `models/trace` directory. You can visualize the trace analysis using the Chrome web browser's Trace Event Profiling Tool (chrome://tracing). This will help you understand the performance of the model and optimize it for better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cda200",
   "metadata": {},
   "source": [
    "There can be `OpenTelemetry trace error occurred. cannot send span to the batch span processor because the channel is full` warning messages when writing the trace file. But you can ignore them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a948a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warboy_vision_models.tests.e2e.test_npu_performance import test_warboy_performance\n",
    "\n",
    "test_warboy_performance(\n",
    "    cfg = cfg,\n",
    "    num_device = 1,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "furiosa-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
